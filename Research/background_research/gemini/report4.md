# **Gen3 Lite 매니퓰레이터를 활용한 일반 객체 파지 연구 보고서**

**1\. 서론 (Introduction) (3페이지)**

매니퓰레이터 암은 현대 산업 자동화뿐만 아니라 서비스 로봇, 의료, 그리고 심지어 가정 환경에 이르기까지 그 활용 범위가 점차 확대되고 있으며, 지능형 시스템 개발에 있어 핵심적인 요소로 자리매김하고 있습니다. 특히, 인간과 로봇 간의 협업이 증가함에 따라, 로봇이 다양한 형태, 크기, 재질을 가진 "일반 객체"를 안전하고 효율적으로 파지하는 능력은 더욱 중요해지고 있습니다. 기존의 로봇 파지 기술은 특정한 물체나 잘 정의된 환경에 맞춰 설계된 경우가 많아, 실제 다양한 환경에서 마주할 수 있는 일반적인 객체에 대한 범용적인 파지 성능을 확보하는 데 어려움이 있었습니다. \[User Query (entirety)\]

이러한 배경 속에서, 본 연구는 Kinova 사의 Gen3 Lite 매니퓰레이터를 이용하여 실내 환경에서 다양한 일반 객체를 실시간으로 파지하는 것을 목표로 합니다. 실시간성은 실제 작업 환경에서의 효율성을 높이는 데 필수적인 요소이며, 다양한 객체에 대한 파지 능력은 로봇의 활용 가능성을 크게 확장시킬 수 있습니다. 이를 위해 본 연구에서는 두 가지 첨단 방법론, 즉 강화학습 기반의 파지 기술과 비전-언어 모델(Vision-Language Model, VLM) 기반의 인식 기술을 활용한 파지 기술을 탐구하고 비교 분석하고자 합니다. \[User Query (entirety)\]

본 연구의 주요 목표는 다음과 같습니다. 첫째, 강화학습 기반의 접근 방식을 통해 Gen3 Lite 매니퓰레이터가 다양한 일반 객체를 실시간으로 파지할 수 있는 가능성을 실증적으로 검증하는 것입니다. 둘째, 최신 VLM 기반의 인식 시스템과 로봇 매니퓰레이터 제어에 널리 사용되는 MoveIt 2 프레임워크를 결합하여 Gen3 Lite 매니퓰레이터의 일반 객체 파지 능력을 향상시키는 새로운 방법을 제시하는 것입니다. 셋째, 이 두 가지 서로 다른 접근 방식의 성능을 다양한 평가 지표를 통해 비교 분석함으로써 각 방법론의 장단점을 명확히 파악하고, 최종적으로 본 연구의 결과를 바탕으로 향후 모바일 매니퓰레이터 시스템으로 확장하기 위한 기반을 마련하는 것입니다. \[User Query (entirety), (1), (2), (3), (4), (5)\]

본 보고서는 이러한 연구 목표를 달성하기 위해 다음과 같이 구성됩니다. 2장에서는 강화학습 및 VLM 기반 로봇 파지 관련 연구 동향과 Gen3 Lite 매니퓰레이터에 대한 기존 연구를 심층적으로 살펴봅니다. 3장에서는 강화학습 기반 파지 방법과 VLM 기반 파지 방법을 각각의 핵심 아이디어와 구현 방안을 중심으로 상세하게 설명합니다. 4장에서는 실험 설계, 실험 환경 구성, 실험 대상 객체의 선정 기준 및 목록, 성능 평가를 위한 지표, 그리고 각 방법론에 따른 구체적인 실험 절차에 대해 자세히 기술합니다. 5장에서는 실험을 통해 예상되는 결과를 분석하고, 각 방법론의 장단점, 실시간 파지 가능성, 그리고 향후 모바일 매니퓰레이터로의 확장 가능성에 대해 심도 깊은 논의를 펼칩니다. 마지막으로 6장에서는 본 연구의 주요 결과를 요약하고 결론을 제시하며, 향후 연구 방향을 제안하는 것으로 보고서를 마무리합니다. \[Initial Plan\]

**2\. 관련 연구 (Related Research) (5페이지)**

**(1) 강화학습 기반 로봇 파지 연구 동향**

로봇 파지 분야에서 강화학습은 복잡하고 예측 불가능한 환경 하에서 로봇이 스스로 최적의 제어 정책을 학습할 수 있도록 하는 강력한 접근 방식으로 주목받고 있습니다. 특히, 명시적인 모델링 없이도 다양한 센서 데이터를 기반으로 로봇의 행동을 결정할 수 있다는 점에서, 불확실성이 높은 실제 환경에서의 로봇 작업에 큰 잠재력을 보여줍니다. 본 연구에서는 이러한 강화학습 기반 로봇 파지 연구의 최근 동향을 살펴보고, 본 연구에 적용될 수 있는 주요 알고리즘 및 사례를 분석합니다. \[(1), (3), (5)\]

**(a) 다양한 강화학습 알고리즘 소개 (예: DQN, PPO, SAC)**

로봇 파지 연구에 활용되는 대표적인 강화학습 알고리즘으로는 Deep Q-Network (DQN), Proximal Policy Optimization (PPO), 그리고 Soft Actor-Critic (SAC) 등이 있습니다. DQN은 주로 이산적인 행동 공간을 다루는 데 효과적인 알고리즘으로, 로봇의 가능한 파지 동작들을 개별적인 행동으로 정의하고 각각의 가치를 학습하는 데 사용될 수 있습니다. 반면, PPO와 SAC는 연속적인 행동 공간을 직접적으로 다룰 수 있어, 로봇 팔의 섬세한 움직임 제어에 더 적합합니다. 특히, PPO는 비교적 안정적인 학습 성능을 보이며, SAC는 높은 샘플 효율성과 탐험 능력을 자랑합니다. 본 연구에서는 Gen3 Lite 매니퓰레이터의 부드러운 움직임 제어를 위해 연속적인 행동 공간을 효과적으로 다룰 수 있는 PPO 또는 SAC 알고리즘을 주요하게 고려할 수 있습니다. \[(1), (3), (5)\]

**(b) 시뮬레이션 환경 및 실제 로봇 적용 사례**

강화학습 기반 로봇 파지 연구는 실제 로봇 환경에서의 데이터 수집의 어려움과 안전 문제 때문에, Gazebo, MuJoCo, PyBullet 등과 같은 물리 기반 시뮬레이션 환경에서 활발히 진행되고 있습니다. 시뮬레이션 환경은 다양한 시나리오와 객체에 대한 대량의 학습 데이터를 효율적으로 생성할 수 있다는 장점을 제공합니다. 하지만 시뮬레이션 환경과 실제 로봇 환경 간의 차이(sim-to-real gap)는 학습된 정책을 실제 로봇에 그대로 적용하는 데 있어 중요한課題로 작용합니다. 이러한 sim-to-real 문제를 해결하기 위해 domain randomization, adaptive training, meta-learning 등 다양한 연구들이 진행되고 있으며, 시뮬레이션에서 학습된 정책을 실제 로봇에 성공적으로 적용한 사례들이 보고되고 있습니다. 본 연구에서도 시뮬레이션 환경을 활용하여 초기 학습을 진행하고, 실제 Gen3 Lite 매니퓰레이터에 적용하는 방안을 고려할 수 있습니다. \[(1), (3), (5)\]

**(c) 일반 객체 파지를 위한 연구 사례**

다양한 형태, 크기, 재질을 가진 일반 객체를 로봇이 성공적으로 파지하는 것은 강화학습 기반 로봇 파지 연구의 중요한 목표 중 하나입니다. 이를 위해 이미지, 포인트 클라우드 등 다양한 센서 데이터를 입력으로 사용하여 로봇에게 파지 동작을 학습시키는 연구들이 활발히 진행되고 있습니다. 또한, 학습된 정책의 일반화 성능을 향상시키기 위해 다양한 객체 모델을 활용한 학습, 객체의 속성 정보를 상태 공간에 포함하는 방법, 그리고 메타 러닝이나 curriculum learning과 같은 학습 전략들이 연구되고 있습니다. 본 연구에서는 이러한 기존 연구들의 접근 방식을 참고하여 Gen3 Lite 매니퓰레이터가 다양한 일반 객체를 효과적으로 파지할 수 있는 강화학습 모델을 설계하고자 합니다. \[(1), (3), (5)\]

**(2) VLM 기반 로봇 파지 연구 동향**

최근 인공지능 분야에서 비약적인 발전을 이룬 비전-언어 모델(Vision-Language Model, VLM)은 이미지와 텍스트 정보를 동시에 이해하고 연결할 수 있는 강력한 능력을 바탕으로 로봇 인식 및 조작 분야에서도 혁신적인 변화를 가져오고 있습니다. 특히, 자연어 명령을 이해하고 시각적 정보를 기반으로 작업을 수행할 수 있는 VLM의 잠재력은 로봇의 활용 가능성을 크게 확장시킬 것으로 기대됩니다. 본 연구에서는 VLM을 활용한 로봇 파지 연구의 최신 동향을 살펴보고, 본 연구에 적용될 수 있는 주요 모델 및 사례를 분석합니다. \[(2), (4), (5)\]

**(a) 주요 VLM 모델 소개 (예: CLIP, ViT-Grasp, LSeg)**

로봇 파지 연구에 활용될 수 있는 주요 VLM 모델로는 CLIP (Contrastive Language-Image Pre-training), ViT-Grasp (Vision Transformer for Grasping), 그리고 LSeg (Language-based Image Segmentation) 등이 있습니다. CLIP은 이미지와 텍스트 간의 의미적 유사성을 학습하여, 이미지에 대한 설명을 텍스트로 이해하거나, 텍스트 설명에 맞는 이미지를 검색하는 등의 작업을 수행할 수 있습니다. ViT-Grasp는 Vision Transformer 구조를 기반으로 파지 가능성을 직접 예측하는 모델로, 이미지 입력만으로 로봇의 파지 동작을 생성할 수 있습니다. LSeg는 언어적 설명을 기반으로 이미지 내의 특정 영역을 분할하는 모델로, 사용자의 자연어 명령에 따라 특정 객체를 정확하게 인식하고 분할하는 데 활용될 수 있습니다. 본 연구에서는 일반 객체 인식 및 파지를 위해 CLIP의 강력한 시각-언어 이해 능력과 ViT-Grasp의 파지 예측 능력을 함께 고려하거나, LSeg를 활용하여 특정 객체를 정확하게 인식하는 방안을 모색할 수 있습니다. \[(2), (4), (5)\]

**(b) VLM을 활용한 객체 인식 및 파지 계획 연구 사례**

VLM은 로봇에게 단순히 객체의 종류를 인식하는 것을 넘어, 객체의 속성, 기능, 그리고 사용자와의 상호작용 의도까지 이해할 수 있는 능력을 부여합니다. 로봇 파지 연구에서는 VLM을 이용하여 특정 객체를 인식하고, 인식된 정보를 바탕으로 적절한 파지 자세를 계획하는 연구들이 활발히 진행되고 있습니다. 예를 들어, 자연어 명령 "빨간색 컵을 잡아줘"를 이해하고 이미지에서 빨간색 컵을 찾아 파지하거나, "책상 위에 있는 물건을 치워줘"라는 명령에 따라 책상 위의 다양한 객체들을 인식하고 순서대로 파지하여 옮기는 등의 작업이 가능해집니다. 이러한 연구들은 VLM이 로봇 파지 시스템의 유연성과 범용성을 크게 향상시킬 수 있음을 보여줍니다. 본 연구에서도 VLM을 활용하여 Gen3 Lite 매니퓰레이터가 다양한 일반 객체를 효과적으로 인식하고 파지할 수 있는 시스템을 구축하는 것을 목표로 합니다. \[(2), (4), (5)\]

**(c) MoveIt 2를 이용한 로봇 제어 연구**

MoveIt 2는 로봇 팔의 기구학적 모델링, 모션 계획, 충돌 회피, 센서 통합 등 로봇 매니퓰레이션을 위한 다양한 기능을 제공하는 강력한 오픈 소스 프레임워크입니다. 로봇 파지 연구에서는 MoveIt 2를 이용하여 VLM과 같은 인식 시스템으로부터 얻은 객체의 위치 및 자세 정보를 기반으로 안전하고 효율적인 파지 자세를 계획하고, 로봇 팔의 움직임 경로를 생성하는 데 널리 활용됩니다. MoveIt 2는 다양한 모션 계획 알고리즘을 제공하며, 사용자는 로봇의 작업 환경과 목표에 따라 적절한 알고리즘을 선택하여 사용할 수 있습니다. 또한, MoveIt 2는 실제 로봇 하드웨어와의 인터페이스를 제공하여, 계획된 움직임 경로를 실제 로봇에 전송하고 실행할 수 있도록 지원합니다. 본 연구에서는 VLM 기반 인식 시스템과 MoveIt 2를 통합하여 Gen3 Lite 매니퓰레이터의 일반 객체 파지 작업을 효율적으로 수행하는 방법을 연구하고자 합니다. \[(2), (4), (5)\]

**(3) Gen3 Lite 매니퓰레이터 관련 연구**

Kinova Gen3 Lite 매니퓰레이터는 7개의 자유도를 가지며, 경량화된 디자인과 다양한 센서를 탑재하고 있어 연구 및 교육 목적으로 널리 사용되는 로봇 팔입니다. 본 연구에서는 Gen3 Lite 매니퓰레이터를 활용한 기존 연구들을 조사하여, 이 로봇 팔의 특징과 성능, 그리고 파지 작업에서의 활용 사례를 파악합니다. 특히, Gen3 Lite의 내장된 힘/토크 센서, 다양한 엔드 이펙터 옵션, 그리고 ROS (Robot Operating System) 기반의 제어 인터페이스 등을 고려하여 본 연구에 적합한 파지 전략을 구상하는 데 참고할 만한 정보를 수집합니다. 또한, Gen3 Lite 매니퓰레이터의 운동학적 및 동역학적 특성을 분석하여 강화학습 모델 설계 및 MoveIt 2를 이용한 모션 계획에 필요한 파라미터를 설정하는 데 활용할 것입니다. \[User Query (mentions "Gen3 Lite 모델")\]

**3\. 연구 방법론 (Research Methodology) (8페이지)**

**(1) 강화학습 기반 파지 방법**

본 연구에서는 Gen3 Lite 매니퓰레이터가 다양한 일반 객체를 실시간으로 파지할 수 있도록 강화학습 기반의 제어 정책을 학습시키는 방법을 탐구합니다. 이를 위해 시뮬레이션 환경을 구축하고, 실제 로봇 환경에서의 실험을 병행하여 연구를 진행할 계획입니다. \[(1), (3), (5)\]

**(a) 환경 설정 (시뮬레이션 및 실제 환경)**

강화학습 에이전트의 효율적인 학습을 위해 물리 엔진 기반의 시뮬레이션 환경을 구축합니다. 여기에는 Gen3 Lite 매니퓰레이터의 3D 모델, 다양한 형태와 재질의 일반 객체 모델, 그리고 로봇에 장착될 카메라 센서 모델이 포함됩니다. 물리 엔진으로는 사실적인 물리 시뮬레이션을 제공하는 MuJoCo 또는 ROS와의 호환성이 뛰어난 Gazebo를 고려하고 있습니다. 시뮬레이션 환경은 실제 환경과 최대한 유사하게 구성하여 학습된 정책의 실제 로봇으로의 이전(sim-to-real transfer)을 용이하게 합니다. \[User Query (mentions "indoor environment" and "책상 위")\]

실제 실험 환경은 사용자가 언급한 "책상 위" 환경으로 설정합니다. 가로 1.2m, 세로 0.8m, 높이 0.75m 크기의 책상 위에 Gen3 Lite 매니퓰레이터를 안전하게 고정하고, 다양한 실험 대상 객체들을 준비합니다. 객체의 종류와 배치는 실험의 목적에 따라 체계적으로 관리될 것입니다. 객체 인식 및 파지 과정을 관찰하고 데이터를 수집하기 위해 RGB-D 카메라(예: Intel RealSense)를 책상 위 적절한 위치에 설치합니다. 실험 환경의 조명 조건은 일정하게 유지하여 시각 정보의 변화를 최소화합니다. \[User Query (mentions "indoor environment" and "책상 위")\]

**(b) 강화학습 모델 설계 (상태 공간, 행동 공간, 보상 함수)**

강화학습 에이전트의 상태는 로봇의 현재 관절 각도, 그리퍼의 개폐 상태, 그리고 카메라로부터 얻은 시각 정보(예: 객체의 이미지 또는 특징 벡터)를 포함할 수 있습니다. 실시간 파지를 위해서는 상태 공간의 차원을 적절히 설계하고, 불필요한 정보를 제거하여 학습의 효율성을 높이는 것이 중요합니다. 행동 공간은 로봇 엔드 이펙터의 3차원 위치 및 회전 각도의 변화량, 또는 각 관절의 목표 각도나 속도 등을 포함할 수 있습니다. 그리퍼의 열고 닫는 동작은 별도의 이산적인 행동으로 정의할 수 있습니다. Gen3 Lite 매니퓰레이터의 제어 방식을 고려하여 가장 적합한 행동 공간을 설계할 것입니다. \[(1), (3), (5)\]

보상 함수는 강화학습 에이전트가 원하는 목표를 달성하도록 유도하는 역할을 합니다. 본 연구에서는 성공적인 파지에 대해 높은 양의 보상을 제공하고, 파지 실패, 로봇과 환경 또는 객체와의 충돌, 불필요한 움직임 등에 대해서는 음의 보상을 제공하는 방식으로 보상 함수를 설계합니다. 또한, 실시간 파지를 장려하기 위해 파지 완료 시간과 관련된 보상을 추가적으로 고려할 수 있습니다. 예를 들어, 더 짧은 시간 안에 안정적인 파지를 달성했을 경우 더 높은 보상을 제공하는 방식입니다. \[(1), (3), (5)\]

**(c) 학습 알고리즘 및 파라미터 설정**

본 연구에서는 연속적인 행동 공간을 효과적으로 다루고 안정적인 학습 성능을 보이는 PPO (Proximal Policy Optimization) 또는 SAC (Soft Actor-Critic) 알고리즘을 주요 학습 알고리즘으로 사용할 것을 고려하고 있습니다. PPO는 정책 경사(Policy Gradient) 알고리즘의 일종으로, 신뢰 영역 최적화(Trust Region Optimization) 기법을 사용하여 학습의 안정성을 높입니다. SAC는 액터-크리틱(Actor-Critic) 기반의 알고리즘으로, 엔트로피 최대화(Entropy Maximization) 개념을 도입하여 탐험 능력을 향상시키고 더 robust한 정책을 학습할 수 있도록 합니다. 선택된 알고리즘의 학습률, 배치 크기, 에포크 수, 감가율 등 주요 하이퍼파라미터는 실험적으로 조정하여 최적의 성능을 얻도록 합니다. 학습 과정에서는 다양한 탐험 전략(예: ε-greedy, Gaussian noise)을 사용하여 에이전트가 다양한 행동을 시도하고 최적의 정책을 찾도록 유도합니다. \[(1), (3), (5)\]

**(d) 실시간 파지 제어 전략**

학습된 강화학습 정책은 실제 Gen3 Lite 매니퓰레이터에 탑재된 컴퓨터에서 실행되어 실시간으로 파지 동작을 제어합니다. 정책은 로봇의 현재 상태(센서 데이터)를 입력으로 받아 로봇의 행동(예: 관절 속도 명령)을 출력합니다. 실시간 성능을 확보하기 위해 정책 실행에 필요한 계산 시간을 최소화하고, 필요에 따라 저수준 제어기와 통합하여 로봇의 움직임을 부드럽고 정확하게 제어합니다. 파지 과정에서 물체의 미끄러짐이나 예상치 못한 외력 등 외부 환경 변화에 robust하게 대처하기 위해, 로봇에 장착된 힘/토크 센서로부터의 피드백을 활용하는 방안도 고려할 수 있습니다. \[(1), (3), (5)\]

**(2) VLM 기반 파지 방법**

본 연구에서는 비전-언어 모델(VLM)을 활용하여 Gen3 Lite 매니퓰레이터가 다양한 일반 객체를 인식하고 파지하는 방법을 연구합니다. VLM을 통해 얻은 객체의 정보와 MoveIt 2 프레임워크를 결합하여 파지 계획 및 로봇 제어를 수행할 계획입니다. \[(2), (4), (5)\]

**(a) 객체 인식 및 특징 추출을 위한 VLM 활용**

일반 객체 인식 및 파지를 위해 CLIP (Contrastive Language-Image Pre-training) 또는 ViT-Grasp (Vision Transformer for Grasping)와 같은 최신 VLM 모델을 활용합니다. CLIP은 이미지와 텍스트 간의 연관성을 학습하여 이미지에 대한 설명을 이해하거나, 텍스트 설명에 맞는 이미지를 식별하는 데 강력한 성능을 보입니다. ViT-Grasp는 이미지에서 직접 파지 가능성을 예측하는 데 특화된 모델입니다. 로봇에 장착된 RGB-D 카메라로부터 얻은 이미지 데이터를 VLM 모델에 입력하여 객체의 종류, 위치, 자세 등의 정보를 추출합니다. 필요에 따라 VLM 모델의 출력을 후처리하여 파지 계획에 더 적합한 형태로 변환하거나, 객체의 크기, 질감, 대칭성 등 추가적인 특징 정보를 추정하는 방법을 연구합니다. \[(2), (4), (5)\]

**(b) MoveIt 2를 이용한 파지 자세 계획 및 경로 생성**

VLM으로부터 얻은 객체의 3차원 위치 및 자세 정보를 MoveIt 2 프레임워크의 입력으로 사용합니다. MoveIt 2의 grasp generation 기능을 활용하여 인식된 객체에 대해 다양한 접근 방향과 파지 자세를 생성하고, 로봇의 운동학적 제약 조건과 작업 공간 내에서의 충돌 가능성을 고려하여 최적의 파지 자세를 선택합니다. 선택된 파지 자세를 목표로 하여, MoveIt 2의 motion planning 기능을 이용하여 현재 로봇의 자세에서 목표 파지 자세까지 안전하고 효율적인 움직임 경로를 생성합니다. MoveIt 2는 다양한 모션 플래닝 알고리즘(예: RRT, PRM)을 제공하며, 실험 환경과 객체의 특성에 따라 가장 적합한 알고리즘을 선택하여 사용할 것입니다. \[(2), (4), (5)\]

**(c) 센서 데이터 융합 및 실시간 처리**

카메라를 통해 얻은 시각 정보 외에도, Gen3 Lite 매니퓰레이터에 내장된 힘/토크 센서로부터 얻은 데이터를 파지 동작의 안정성을 높이는 데 활용하는 방안을 고려합니다. 예를 들어, 파지 과정에서 힘 센서 데이터를 실시간으로 모니터링하여 객체가 미끄러지거나 과도한 힘이 가해지는 상황을 감지하고, 이에 따라 파지력을 조절하거나 파지 자세를 미세하게 조정하는 등의 피드백 제어를 수행할 수 있습니다. VLM 기반 인식, 파지 계획, 경로 생성 및 실행의 전 과정을 실시간으로 처리하기 위해 각 단계의 알고리즘 효율성을 최적화하고, 필요에 따라 GPU와 같은 병렬 처리 장치를 활용하여 계산 속도를 향상시킬 것입니다. \[(2), (4), (5)\]

**(d) 파지 실행 및 피드백 제어**

MoveIt 2를 통해 생성된 최적의 움직임 경로는 Gen3 Lite 매니퓰레이터의 제어 인터페이스를 통해 로봇 팔에 전달되어 실제 파지 동작을 수행합니다. 파지 동작이 실행되는 동안 로봇의 각 관절의 위치 및 속도 정보를 실시간으로 모니터링하고, 계획된 경로를 정확하게 추종하도록 PID 제어와 같은 피드백 제어 방식을 적용합니다. 파지가 성공적으로 이루어졌는지 여부는 그리퍼에 장착된 센서 또는 카메라를 통해 확인하고, 파지에 실패한 경우에는 실패 원인을 분석하여 파지 동작을 재시도하거나 다른 파지 전략을 시도하는 등의 오류 처리 메커니즘을 구현할 수 있습니다. \[(2), (4), (5)\]

**4\. 실험 설계 및 환경 (Experimental Design and Environment) (4페이지)**

**(1) 실험 목표 및 가설**

본 연구의 실험은 강화학습 기반 파지 방법과 VLM 기반 파지 방법의 성능을 다양한 일반 객체에 대해 평가하고 비교하는 것을 주요 목표로 합니다. 구체적으로는 각 방법론의 파지 성공률, 파지 소요 시간, 그리고 파지된 객체의 안정성을 측정하여 실시간 일반 객체 파지 능력 측면에서 각 방법론의 장단점을 분석하고자 합니다.

본 연구의 주요 가설은 다음과 같습니다. 첫째, VLM 기반 파지 방법은 강화학습 기반 파지 방법에 비해 학습되지 않은 새로운 객체에 대한 파지 성공률이 더 높을 것이다. 이는 VLM의 뛰어난 시각적 일반화 능력에 기반합니다. 둘째, 강화학습 기반 파지 방법은 특정 객체에 대해 최적화된 정책을 학습함으로써 VLM 기반 방법보다 더 빠른 파지 속도를 보일 수 있다. 셋째, 두 방법론 모두 실내 환경에서 Gen3 Lite 매니퓰레이터를 이용하여 다양한 형태, 크기, 재질의 일반 객체를 안정적으로 파지할 수 있을 것이다. \[All snippets contribute to defining the overall research goals\]

**(2) 실험 환경 구성 (Gen3 Lite 매니퓰레이터, 책상, 카메라 등)**

실험은 일반적인 실내 환경, 구체적으로는 가로 1.2m, 세로 0.8m, 높이 0.75m의 나무 책상 위에서 진행됩니다. Kinova Gen3 Lite 매니퓰레이터는 책상의 한쪽 모서리에 견고하게 설치됩니다. 객체의 인식 및 파지 과정을 촬영하고 데이터를 수집하기 위해 Intel RealSense D435와 같은 RGB-D 카메라를 책상 위 적절한 위치에 삼각대를 이용하여 고정합니다. 카메라는 객체를 전체적으로 잘 조망할 수 있도록 설치하며, 필요에 따라 추가적인 조명 장치를 사용하여 실험 환경의 밝기를 일정하게 유지합니다. \[User Query (mentions "Gen3 Lite 모델," "indoor environment," and "책상 위")\]

**(3) 실험 대상 객체 (다양한 형태, 크기, 재질의 객체 선정 기준)**

실험 대상 객체는 일상생활에서 흔히 볼 수 있는 다양한 형태, 크기, 재질의 물건들로 선정합니다. 객체의 형태는 원기둥, 직육면체, 구, 그리고 불규칙한 형태를 포함하며, 크기는 최대 길이 15cm 이내로 제한합니다. 재질은 플라스틱, 금속, 나무, 세라믹, 종이 등 다양하게 구성하여 각 방법론의 일반적인 객체 파지 능력을 종합적으로 평가할 수 있도록 합니다. 총 10가지의 서로 다른 객체를 선정하여 실험을 진행합니다. \[User Query (mentions "general하게 모든 객체," "rigid body," and "단순한 물체")\]

**Key Table:** Table of Experimental Objects

| 객체 ID | 형태 | 대략적인 크기 (cm) | 재질 |
| :---- | :---- | :---- | :---- |
| 1 | 원기둥 | 지름: 5, 높이: 10 | 플라스틱 |
| 2 | 직육면체 | 6x6x6 | 나무 |
| 3 | 구 | 지름: 8 | 금속 |
| 4 | 머그컵 | 높이: 9, 지름: 8 | 세라믹 |
| 5 | 장난감 자동차 | 길이: 12, 폭: 5, 높이: 4 | 플라스틱 |
| 6 | 책 | 20x15x2 | 종이 |
| 7 | 테니스 공 | 지름: 6.7 | 고무 |
| 8 | 물병 | 높이: 18, 지름: 7 | 플라스틱 |
| 9 | 망치 | 길이: 25 | 금속, 나무 |
| 10 | 가위 | 길이: 20 | 금속, 플라스틱 |

**(4) 평가 지표 (파지 성공률, 파지 시간, 안정성 등)**

각 방법론의 성능은 다음과 같은 객관적인 평가 지표를 사용하여 측정합니다.

* **파지 성공률:** 각 객체에 대해 시도한 총 파지 횟수 중에서 객체를 성공적으로 들어 올려 5초 이상 안정적으로 유지한 횟수의 비율로 정의합니다.  
* **파지 시간:** 파지 명령이 시작된 시점부터 객체를 성공적으로 파지하여 들어 올릴 때까지 소요된 시간을 초 단위로 측정합니다.  
* **파지 안정성:** 성공적으로 파지한 객체를 초기 위치에서 수평 방향으로 약 10cm 이동시킨 후에도 객체를 떨어뜨리지 않고 안정적으로 유지하는지 여부를 평가합니다. 추가적으로, 파지한 객체를 가볍게 흔들어 보아 파지의 견고함을 정성적으로 평가할 수 있습니다. \[User Query (mentions "실시간")\]

**(5) 실험 절차 (각 방법론별 실험 단계 상세 설명)**

**강화학습 기반 파지 방법 실험 절차:**

1. 각 실험 대상 객체를 책상 위의 미리 정의된 시작 위치에 무작위 순서로 놓습니다.  
2. 학습된 강화학습 정책을 실행하여 객체 파지를 시도합니다.  
3. 파지 시도 결과(성공 또는 실패)를 기록하고, 성공한 경우 파지에 소요된 시간을 측정합니다.  
4. 파지가 성공한 경우, 파지 안정성 평가를 수행하고 결과를 기록합니다.  
5. 각 객체에 대해 최소 10회 이상 파지를 시도합니다.

**VLM 기반 파지 방법 실험 절차:**

1. 각 실험 대상 객체를 책상 위의 미리 정의된 시작 위치에 무작위 순서로 놓습니다.  
2. VLM 기반 객체 인식 시스템을 통해 객체의 위치 및 자세 정보를 획득합니다.  
3. MoveIt 2를 이용하여 획득한 정보를 바탕으로 파지 자세를 계획하고 로봇 팔의 움직임 경로를 생성합니다.  
4. 생성된 경로를 따라 Gen3 Lite 매니퓰레이터가 파지 동작을 수행합니다.  
5. 파지 시도 결과(성공 또는 실패)를 기록하고, 성공한 경우 파지에 소요된 시간을 측정합니다.  
6. 파지가 성공한 경우, 파지 안정성 평가를 수행하고 결과를 기록합니다.  
7. 각 객체에 대해 최소 10회 이상 파지를 시도합니다.

**5\. 예상 결과 및 논의 (Expected Results and Discussion) (5페이지)**

**(1) 강화학습 기반 파지 실험 예상 결과 및 분석**

강화학습 기반 파지 방법은 학습 과정에서 경험한 객체와 유사한 형태나 특징을 가진 객체에 대해서는 비교적 높은 파지 성공률을 보일 것으로 예상됩니다. 학습된 정책은 특정 객체에 대해 최적화된 파지 전략을 내재하고 있어 빠른 파지 동작을 수행할 수 있을 것입니다. 하지만 학습 데이터에 포함되지 않았거나, 형태가 매우 다른 새로운 객체에 대해서는 일반화 성능이 저하될 가능성이 있습니다. 또한, 강화학습 모델의 성능은 학습 데이터의 양과 질, 그리고 학습 알고리즘의 선택 및 하이퍼파라미터 설정에 크게 의존하므로, 이러한 요소들이 최종 결과에 중요한 영향을 미칠 것입니다. \[(1), (3), (5)\]

**(2) VLM 기반 파지 실험 예상 결과 및 분석**

VLM 기반 파지 방법은 VLM 모델이 다양한 시각적 특징을 학습하고 이해하는 능력이 뛰어나기 때문에, 학습 데이터에 명시적으로 포함되지 않은 새로운 객체에 대해서도 비교적 높은 파지 성공률을 달성할 수 있을 것으로 기대됩니다. 특히, 객체의 형태뿐만 아니라 질감이나 색상과 같은 다양한 속성을 인식하고 이를 파지 계획에 활용할 수 있다는 장점이 있습니다. 파지 시간은 VLM 모델의 추론 속도와 MoveIt 2를 이용한 파지 자세 계획 및 경로 생성 시간에 따라 결정될 것입니다. 실시간 파지를 위해서는 VLM 모델의 효율성을 높이고, MoveIt 2의 파지 계획 시간을 최적화하는 것이 중요합니다. \[(2), (4), (5)\]

**(3) 두 방법론의 성능 비교 및 장단점 분석**

강화학습 기반 방법은 특정 작업에 대해 매우 효율적인 파지 전략을 학습할 수 있다는 장점이 있지만, 새로운 환경이나 객체에 대한 적응력이 떨어지고, 학습에 많은 시간과 컴퓨팅 자원을 필요로 할 수 있습니다. 반면, VLM 기반 방법은 다양한 객체에 대한 높은 일반화 성능을 제공하며, 자연어와 같은 고수준의 명령을 이해하고 작업을 수행할 수 있다는 장점이 있습니다. 하지만 인식 오류가 발생할 수 있으며, 복잡한 객체나 상황에서는 파지 계획의 최적성이 떨어질 수 있습니다. 또한, VLM 모델의 계산 복잡성으로 인해 실시간 성능 확보에 어려움이 있을 수 있습니다.

**(4) 실시간 파지 가능성 및 한계점 논의**

본 연구에서 목표하는 실시간 파지 능력은 실제 로봇이 인간과 상호작용하거나 자동화된 작업 흐름에 통합되기 위해 필수적인 요소입니다. 강화학습 기반 방법은 학습된 정책을 실행하는 데 비교적 적은 계산 자원을 필요로 하므로 잠재적으로 빠른 응답 시간을 가질 수 있지만, 복잡한 상태 공간이나 행동 공간을 다루는 경우 실시간 제어가 어려워질 수 있습니다. VLM 기반 방법은 객체 인식 및 파지 계획 단계에서 상당한 계산 시간이 소요될 수 있으므로, 실시간 성능을 확보하기 위해서는 모델 경량화 및 알고리즘 최적화가 필수적입니다. 또한, 센서 데이터 처리 속도와 로봇 제어기의 응답 속도 등 시스템 전체의 성능이 실시간 파지 가능성에 영향을 미칠 것입니다. \[User Query (emphasizes "실시간" performance)\]

**(5) 향후 모바일 매니퓰레이터 확장 가능성**

본 연구에서 탐구하는 강화학습 기반 및 VLM 기반 파지 기술은 향후 Gen3 Lite 매니퓰레이터를 모바일 베이스와 통합하여 이동 기능을 갖춘 모바일 매니퓰레이터 시스템으로 확장하는 데 중요한 기반이 될 수 있습니다. 강화학습 기반 방법은 이동 로봇의 네비게이션 및 환경 인식과 파지 동작을 통합적으로 학습시켜 더욱 복잡한 작업을 수행할 수 있도록 발전시킬 수 있습니다. VLM 기반 방법은 모바일 로봇이 다양한 환경에서 특정 객체를 자연어 명령이나 시각적 정보를 기반으로 인식하고 파지하는 데 매우 유용하게 활용될 수 있습니다. 다만, 모바일 환경에서의 동적인 요소, 예를 들어 이동 중의 객체 인식 및 파지, 변화하는 환경에 대한 적응 등 새로운 기술적課題들에 대한 추가적인 연구가 필요합니다. \[User Query (mentions the future plan to extend to a "mobile base")\]

**6\. 결론 및 향후 연구 방향 (Conclusion and Future Research Directions) (3페이지)**

**(1) 연구 결과 요약 및 의의**

본 연구는 Kinova Gen3 Lite 매니퓰레이터를 이용하여 실내 환경에서 다양한 일반 객체를 실시간으로 파지하는 것을 목표로 강화학습 기반 방법과 VLM 기반 방법을 탐구하고 비교 분석했습니다. 각 방법론의 핵심 아이디어, 구현 방안, 그리고 실험을 통해 예상되는 결과를 상세히 논의했습니다. 본 연구는 로봇 파지 기술 분야에서 중요한 두 가지 최신 접근 방식을 실제 로봇 플랫폼에 적용하고 비교함으로써, 각 방법론의 장단점을 명확히 하고 향후 연구 방향을 제시하는 데 기여할 수 있을 것으로 기대됩니다.

**(2) 연구의 한계점 및 개선 방안**

본 연구는 실험 대상 객체의 종류와 실험 환경이 제한적일 수 있으며, 강화학습 기반 방법의 경우 학습에 필요한 데이터 양과 학습 시간, VLM 기반 방법의 경우 모델의 계산 복잡성으로 인한 실시간 성능 확보의 어려움 등의 한계점을 가질 수 있습니다. 향후 연구에서는 더 다양한 형태와 재질의 객체를 대상으로 실험을 진행하고, 보다 효율적인 강화학습 알고리즘 개발 및 경량화된 VLM 모델을 적용하는 방안을 모색하여 연구의 범위를 확장하고 실용성을 높일 필요가 있습니다.

**(3) 향후 연구 방향 제시 (복잡한 객체 파지, 모바일 매니퓰레이터 통합, 새로운 알고리즘 적용 등)**

본 연구의 결과를 바탕으로 다음과 같은 향후 연구 방향을 제시합니다. 첫째, 단순한 형태의 rigid body뿐만 아니라, 변형 가능한 객체나 다관절 객체와 같이 더욱 복잡한 형태의 객체를 파지하는 연구를 진행할 수 있습니다. 둘째, 본 연구에서 개발된 파지 기술을 모바일 로봇 플랫폼에 통합하여 이동 중에도 객체를 인식하고 파지할 수 있는 모바일 매니퓰레이터 시스템을 개발하는 연구를 진행할 수 있습니다. 셋째, 현재 연구되고 있는 최첨단 강화학습 알고리즘이나 새로운 VLM 모델을 적용하여 파지 성능을 더욱 향상시키는 연구를 수행할 수 있습니다. 또한, cluttered environment에서의 객체 파지, 불확실한 객체 포즈 추정 등 더욱 현실적인 작업 환경에서의 로봇 파지 문제를 해결하기 위한 연구도 필요합니다. \[User Query (mentions "복잡한 객체" and "mobile base와 결합한 mobile manipulator" as future research directions)\]

**7\. 참고 문헌 (References) (2페이지)**

본 보고서에서 인용된 모든 학술 논문, 서적 및 기타 참고 자료 목록은 추후 작성될 예정입니다.